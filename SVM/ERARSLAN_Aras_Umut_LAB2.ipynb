{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clothes Classification with Support Vector Machines\n",
    "\n",
    "In this notebook we are going to explore the use of Support Vector Machines (SVM) for image classification. We will use a new version of the famous MNIST dataset (the original is a dataset of handwritten digits). The version we are going to use is called Fashion MNIST (https://pravarmahajan.github.io/fashion/) and is a dataset of small images of clothes and accessories.\n",
    "\n",
    "\n",
    "\n",
    "The dataset labels are the following:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Insert your surname, name and ID number\n",
    "\n",
    "Student surname: ERARSLAN\n",
    "\n",
    "Student name: Aras Umut\n",
    "    \n",
    "ID: 2005627"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the required packages\n",
    "\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to load Fashion MNIST dataset\n",
    "def load_mnist(path, kind='train'):\n",
    "    import os\n",
    "    import gzip\n",
    "    import numpy as np\n",
    "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz' % kind)\n",
    "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz' % kind)\n",
    "    with gzip.open(labels_path, 'rb') as lbpath:\n",
    "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8,offset=8)\n",
    "    with gzip.open(images_path, 'rb') as imgpath:\n",
    "        images = np.frombuffer(imgpath.read(), dtype=np.uint8,offset=16).reshape(len(labels), 784)\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix your ID (\"numero di matricola\") and the seed for random generator (as usual you can try different seeds)\n",
    "ID = 2005627\n",
    "np.random.seed(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000,)\n"
     ]
    }
   ],
   "source": [
    "#load the Fashion MNIST dataset from the 'data' folder and let's normalize the features so that each value is in [0,1] \n",
    "\n",
    "X, y = load_mnist('data', kind='train')\n",
    "# rescale the data\n",
    "X, y = X / 255., y # original pixel values are between 0 and 255\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split into training and test. Make sure that each label is present at least 10 times\n",
    "in training. If it is not, then keep adding permutations to the initial data until this \n",
    "happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels in training dataset:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Frequencies in training dataset:  [71 64 59 72 66 54 53 48 54 59]\n"
     ]
    }
   ],
   "source": [
    "# Random permute the data and split into training and test taking the first 600\n",
    "# data samples as training and 4000 samples as test\n",
    "permutation = np.random.permutation(X.shape[0])\n",
    "\n",
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 600\n",
    "m_test = 4000\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:m_training+m_test:]\n",
    "y_train, y_test = y[:m_training], y[m_training:m_training+m_test:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for plotting a image and printing the corresponding label\n",
    "def plot_input(X_matrix, labels, index):\n",
    "    print(\"INPUT:\")\n",
    "    plt.imshow(\n",
    "        X_matrix[index].reshape(28,28),\n",
    "        cmap          = plt.cm.gray_r,\n",
    "        interpolation = \"nearest\"\n",
    "    )\n",
    "    plt.show()\n",
    "    print(\"LABEL: %i\"%labels[index])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 9\n",
      "INPUT:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LABEL: 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "#let's try the plotting function\n",
    "plot_input(X_train,y_train,random.randrange(10)) #show random images\n",
    "plot_input(X_test,y_test,random.randrange(700))\n",
    "plot_input(X_test,y_test,random.randrange(700))\n",
    "plot_input(X_test,y_test,random.randrange(700))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 1\n",
    "Use a SVM classifier with cross validation to pick a model. Use a 4-fold cross-validation. Let's start with a Linear kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESULTS FOR LINEAR KERNEL\n",
      "Best parameters set found:\n",
      "{'C': 0.1}\n",
      "Score with best parameters:\n",
      "0.7999999999999999\n",
      "All scores on the grid:\n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
      "0       0.213434      0.009952         0.049617        0.002579   0.001   \n",
      "1       0.105468      0.004194         0.036402        0.000499    0.01   \n",
      "2       0.081037      0.002268         0.031167        0.001087     0.1   \n",
      "3       0.085023      0.002271         0.030917        0.001222       1   \n",
      "4       0.085272      0.001496         0.031665        0.001475      10   \n",
      "5       0.085023      0.002579         0.031416        0.001115     100   \n",
      "\n",
      "         params  split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0  {'C': 0.001}           0.633333           0.620000           0.613333   \n",
      "1   {'C': 0.01}           0.780000           0.760000           0.820000   \n",
      "2    {'C': 0.1}           0.786667           0.786667           0.820000   \n",
      "3      {'C': 1}           0.766667           0.773333           0.773333   \n",
      "4     {'C': 10}           0.766667           0.773333           0.773333   \n",
      "5    {'C': 100}           0.766667           0.773333           0.773333   \n",
      "\n",
      "   split3_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0           0.586667         0.613333        0.016997                6  \n",
      "1           0.806667         0.791667        0.023274                2  \n",
      "2           0.806667         0.800000        0.014142                1  \n",
      "3           0.766667         0.770000        0.003333                3  \n",
      "4           0.766667         0.770000        0.003333                3  \n",
      "5           0.766667         0.770000        0.003333                3  \n",
      "0.9633333333333334\n"
     ]
    }
   ],
   "source": [
    "#import SVC\n",
    "from sklearn.svm import SVC\n",
    "#import for Cross-Validation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import pandas as pd\n",
    "\n",
    "# parameters for linear SVM\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "#train linear SVM\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel = 'linear'), parameters, refit = True, verbose = 0, cv=4) # cv 4 means 4 fold, verbose is to print training\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR LINEAR KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\") #max of mean test score in cv_results_\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(\"All scores on the grid:\") #cv_results_ detailed scores/results table\n",
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 2\n",
    "Pick a model for the Polynomial kernel with degree=2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for poly with degree 2 kernel\n",
    "parameters = {'C': [0.05, 0.5, 5],'gamma':[0.05,0.5,5.]}\n",
    "\n",
    "#run SVM with poly of degree 2 kernel\n",
    "\n",
    "grid = GridSearchCV(SVC(kernel = 'poly', degree = 2), parameters, refit = True, verbose = 0, cv=4) # cv 4 means 4 fold, verbose is to print training\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=2 KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\") #max of mean test score in cv_results_\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\") #cv_results_ detailed scores/results table\n",
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 3\n",
    "\n",
    "Now let's try a higher degree for the polynomial kernel (e.g., 4th degree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for poly with higher degree kernel\n",
    "parameters = {'C': [0.05, 0.5, 5],'gamma':[0.05,0.5,5.]}\n",
    "\n",
    "#run SVM with poly of higher degree kernel\n",
    "degree = 4\n",
    "grid = GridSearchCV(SVC(kernel = 'poly', degree = 4), parameters, refit = True, verbose = 0, cv=4) # cv 4 means 4 fold, verbose is to print training\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "print ('RESULTS FOR POLY DEGREE=', degree, ' KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\") #max of mean test score in cv_results_\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\") #cv_results_ detailed scores/results table\n",
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 4\n",
    "Pick a model for the Radial Basis Function kernel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for rbf SVM\n",
    "parameters = {'C': [0.5, 5, 50, 500],'gamma':[0.005, 0.05, 0.5,5]}\n",
    "\n",
    "#run SVM with rbf kernel\n",
    "grid = GridSearchCV(SVC(kernel = 'rbf'), parameters, refit = True, verbose = 0, cv=4) # cv 4 means 4 fold, , verbose is to print training\n",
    "grid.fit(X_train,y_train)\n",
    "\n",
    "print ('RESULTS FOR rbf KERNEL')\n",
    "\n",
    "print(\"Best parameters set found:\")\n",
    "print(grid.best_params_)\n",
    "\n",
    "print(\"Score with best parameters:\") #max of mean test score in cv_results_\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(\"\\nAll scores on the grid:\") #cv_results_ detailed scores/results table\n",
    "print(pd.DataFrame(grid.cv_results_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 1\n",
    "What do you observe when using linear, polynomial and RBF kernels on this dataset ?\n",
    "\n",
    "Firstly polynomial gave the worst results. 2-degree polynomial gave a better score than 4-degree polynomial.\n",
    "Even though linear and RBF are so close to each other, RBF gave a better score. So in this dataset, we can clearly say that the polynomial kernel is eliminated by linear and RBF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 5\n",
    "Report here the best SVM kernel and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "best_SVM = SVC(C = 5.0, gamma = 0.005, kernel = 'rbf') #best is to do 4 (rbf)\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "# (error is 1 - svm.score)\n",
    "\n",
    "training_error = 1 - best_SVM.score(X_train, y_train)\n",
    "test_error = 1 - best_SVM.score(X_test, y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 6\n",
    "\n",
    "Analyze how the classification boundaries depend on the C parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot the data and classification boundaries. \n",
    "\n",
    "\n",
    "def plot_data(model, X_train, y_train, X_test, y_test, train_error, test_error):\n",
    "\n",
    "    def make_meshgrid(x, y, h=.02):\n",
    "        x_min, x_max = x.min() - abs(0.1*x.min()), x.max() + abs(0.1*x.min())\n",
    "        y_min, y_max = y.min() - abs(0.1*y.min()), y.max() + abs(0.1*y.min())\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        return xx, yy\n",
    "\n",
    "    def plot_contours(ax, clf, xx, yy, **params):\n",
    "        Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        out = ax.contourf(xx, yy, Z, **params)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "    # Training set\n",
    "    X0, X1 = X_train_pca[:, 0], X_train_pca[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "    plot_contours(ax[0], model, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax[0].scatter(X0, X1, c=y_train, cmap=plt.cm.coolwarm, s=35, edgecolors='k')\n",
    "    ax[0].set_xticks(())\n",
    "    ax[0].set_yticks(())\n",
    "    ax[0].set_title('Training data, C={:.0e}, model accuracy={:.3f}'.format(model.__dict__['C'],1 - train_error))\n",
    "    \n",
    "    # Test set\n",
    "    X0, X1 = X_test_pca[:, 0], X_test_pca[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "    plot_contours(ax[1], model, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    ax[1].scatter(X0, X1, c=y_test, cmap=plt.cm.coolwarm, s=35, edgecolors='k')\n",
    "    ax[1].set_xticks(())\n",
    "    ax[1].set_yticks(())\n",
    "    ax[1].set_title('Test data, C={:.0e}, model accuracy={:.3f}'.format(model.__dict__['C'],1 - test_error))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Too many test samples for visualization, plot only some of them\n",
    "m_test = 1000\n",
    "p = np.random.permutation(X_test.shape[0])[:m_test]\n",
    "X_test_red, y_test_red = X_test[p,:], y_test[p]\n",
    "\n",
    "# Perform classification only on subset of original classes for better visualization\n",
    "\n",
    "class_list = [0,1,2,3,4] #YOU CAN TRY TO CHANGE THE CLASSES\n",
    "\n",
    "train_idxs = [i for i in range(len(y_train)) if y_train[i] in class_list]   \n",
    "test_idxs = [i for i in range(len(y_test_red)) if y_test_red[i] in class_list] \n",
    "X_train_plot = X_train[train_idxs,:]\n",
    "X_test_plot = X_test_red[test_idxs,:] \n",
    "y_train_plot = y_train[train_idxs]\n",
    "y_test_plot = y_test_red[test_idxs] \n",
    "\n",
    "\n",
    "# The dimensionality is reduced to 2 for visualization using PCA\n",
    "# PCA: Reduce the dimensionality trying to preserve the information content. \n",
    "# PCA will be the topic of one of the very last lectures\n",
    "\n",
    "# Reduce X dimensionality to 2 for visualization\n",
    "pca = PCA(n_components=2, svd_solver='randomized', whiten=True).fit(X_train)\n",
    "X_train_pca, X_test_pca = pca.transform(X_train_plot), pca.transform(X_test_plot)\n",
    "\n",
    "\n",
    "C_list = [1e-1, 1, 1e3, 1e5]\n",
    "gamma = 0.5\n",
    "\n",
    "# Fit the prediction model on train_plot data futher reduced with PCA, \n",
    "# then classify with different prediction models and plot data\n",
    "# Use RBF kernel \n",
    "\n",
    "for C in C_list:\n",
    "    # ADD CODE TO TRAIN SVM (use the PCA reduced data)\n",
    "    my_svm = SVC(C = C, kernel ='rbf', gamma = gamma)\n",
    "    my_svm.fit(X_train_pca, y_train_plot)\n",
    "    \n",
    "    train_error = 1 - my_svm.score(X_train_pca, y_train_plot)\n",
    "    test_error = 1 - my_svm.score(X_test_pca, y_test_plot)\n",
    "    plot_data(my_svm, X_train_pca, y_train_plot, X_test_pca, y_test_plot, train_error, test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 2\n",
    "How do the shape of the boundaries changes when trying different values of C ?\n",
    "\n",
    "C list contains 4 different C values that are going from smaller to higher. On the shapes, the smallest C has the simplest boundaries while the highest C has the most complicated one. That is totally expected because C controls the cost of misclassification on the training data. So, while C is getting higher, it starts to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 7\n",
    "\n",
    "Analyze how the gamma parameter (inversely proportional to standard deviation of Gaussian Kernel) impact the performances of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test with different values of gamma\n",
    "\n",
    "# Set gamma values\n",
    "gamma_values = np.logspace(-5,2,8)\n",
    "print(gamma_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try the SVM with the previously set values of gamma\n",
    "# use rbf kernel and C=1\n",
    "\n",
    "train_acc_list, test_acc_list = [], []\n",
    "\n",
    "    \n",
    "for gamma in gamma_values:\n",
    "    my_svm = SVC(C = 1, kernel ='rbf', gamma = gamma)\n",
    "    my_svm.fit(X_train, y_train)\n",
    "    \n",
    "    train_acc_list.append(my_svm.score(X_train, y_train))\n",
    "    test_acc_list.append(my_svm.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "ax[0].plot(gamma_values, train_acc_list)\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_xlabel('gamma')\n",
    "ax[0].set_ylabel('Train accuracy')\n",
    "ax[0].grid(True)\n",
    "\n",
    "ax[1].plot(gamma_values, test_acc_list)\n",
    "ax[1].set_xscale('log')\n",
    "ax[1].set_xlabel('gamma')\n",
    "ax[1].set_ylabel('Test accuracy')\n",
    "ax[1].grid(True)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 3\n",
    "How do the train and test error change when changing gamma ? Which is the best value of gamma ? \n",
    "Connect your answers to the discussion about the overfitting issue.\n",
    "\n",
    "Same as the C example, here gamma list is going from lower to higher. On the train plot, we can see that at 0.1 gamma, accuracy reaches 100% while on the test plot, accuracy starts decreasing after 0.01. So that means after gamma 0.01, overfit is starting. As we can see, the best gamma we can choose here is 0.01. \n",
    "\n",
    "Best gamma(best test accuracy) = 0.01\n",
    "Overfit starts when a gamma, that is higher than the best gamma, is used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More data\n",
    "Now let's do the same but using more data points for training.\n",
    "\n",
    "\n",
    "Choose a new number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "m_training = 1500 # TODO number of data points, adjust depending on the capabilities of your PC\n",
    "\n",
    "X_train, X_test = X[:m_training], X[m_training:]\n",
    "y_train, y_test = y[:m_training], y[m_training:]\n",
    "\n",
    "labels, freqs = np.unique(y_train, return_counts=True)\n",
    "print(\"Labels in training dataset: \", labels)\n",
    "print(\"Frequencies in training dataset: \", freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 8\n",
    "\n",
    "Let's try to use SVM with parameters obtained from the best model for $m_{training} =  1500$. Since it may take a long time to run, you can decide to just let it run for some time and stop it if it does not complete. If you decide to do this, report it in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get training and test error for the best SVM model from CV\n",
    "\n",
    "best_SVM = SVC(C = 5.0, gamma = 0.005, kernel = 'rbf')\n",
    "best_SVM.fit(X_train, y_train)\n",
    "\n",
    "training_error = 1 - best_SVM.score(X_train, y_train)\n",
    "test_error = 1 - best_SVM.score(X_test, y_test)\n",
    "\n",
    "print (\"Best SVM training error: %f\" % training_error)\n",
    "print (\"Best SVM test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for comparison, let's also use logistic regression \n",
    "\n",
    "## TO DO 9 Try first without regularization (use a very large large C)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C = 1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "training_error = 1 - logreg.score(X_train, y_train)\n",
    "test_error = 1 - logreg.score(X_test, y_test)\n",
    "\n",
    "print (\"Best logistic regression training error: %f\" % training_error)\n",
    "print (\"Best logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 10 Try  with regularization (use C=1)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = linear_model.LogisticRegression(C = 1.0)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "training_error = 1 - logreg.score(X_train, y_train)\n",
    "test_error = 1 - logreg.score(X_test, y_test)\n",
    "\n",
    "print (\"Best regularized logistic regression training error: %f\" % training_error)\n",
    "print (\"Best regularized logistic regression test error: %f\" % test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 4\n",
    "Compare and discuss:\n",
    "- the results from SVM with m=600 and with m=1500 training data points. If you stopped the SVM, include such aspect in your comparison.\n",
    "\n",
    "Best SVM with m=600 gives 0.045 training and 0.219 test error while best SVM with m=1500 gives 0.054 training error and 0.170291 test error. So there is an almost 5% accuracy difference between the 2 options. That means there is a huge difference between accuracies while training with 600 and 1500 data points. An increase in training error has no harm to us, so using higher training data points is the key here to increase our test accuracy. There would be an even lower test error If we would use more than 1500 data points. When I tested it with 5000 data points, I got a 0.14 test error as I expected.\n",
    "\n",
    "- the results of SVM and of Logistic Regression\n",
    "\n",
    "When I tested both with m=1500, the results are; for the best SVM gives 0.054 training error, 0.170291 test error and for the logistic regression (C=1) 0.010667 training error, 0.185282 test error. As we can see, from test errors, our best SVM gives better test accuracy. Also, another important point is, logistic regression gives 0.01 training error while test error is 0.185. The difference between training and test error for logistic regression is a lot bigger than the difference between training and test error of our best SVM. We know that we need to choose a different option between SVM kernels/logistic regression depending on the number of features and number of training examples. In this example(with this dataset and data points), It can be seen that our SVM is a better choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 11\n",
    "Plot an item of clothing that is missclassified by logistic regression and correctly classified by SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_small = X[:3000] # small test list\n",
    "y_small = y[:3000]\n",
    "permutation = np.random.permutation(X_small.shape[0]) # i wanted to see different results\n",
    "X_small = X_small[permutation]\n",
    "y_small = y_small[permutation]\n",
    "\n",
    "LR_prediction = logreg.predict(X_small)\n",
    "SVM_prediction = best_SVM.predict(X_small)\n",
    "\n",
    "for i in range(len(y_small)):\n",
    "    if(LR_prediction[i] != y_small[i]):\n",
    "        if(SVM_prediction[i] == y_small[i]):\n",
    "            print(\"LR Prediction = \" + str(LR_prediction[i]) + \"   SVM Prediction = \" + str(SVM_prediction[i]) + \"   Label = \" + str(y_small[i]))\n",
    "            plot_input(X_small,y_small,i)\n",
    "            break; #stop after 1 item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO 12\n",
    "Plot the confusion matrix for the SVM classifier and for logistic regression.\n",
    "The confusion matrix has one column for each predicted label and one row for each true label. \n",
    "It shows for each class in the corresponding row how many samples belonging to that class gets each possible output label.\n",
    "Notice that the diagonal contains the correctly classified samples, while the other cells correspond to errors.\n",
    "You can obtain it with the sklearn.metrics.confusion_matrix function (see the documentation).\n",
    "Try also to normalize the confusion matrix by the number of samples in each class in order to measure the accuracy on each single class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True) # for better aligned printing of confusion matrix use floatmode='fixed'\n",
    "\n",
    "u, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Labels and frequencies in test set: \", counts)\n",
    "\n",
    "confusion_SVM = confusion_matrix(y_test, best_SVM.predict(X_test), labels)\n",
    "print(\"\\n Confusion matrix SVM  \\n \\n\", confusion_SVM)\n",
    "\n",
    "confusion_LR =  confusion_matrix(y_test, logreg.predict(X_test), labels)\n",
    "print(\"\\n Confusion matrix LR  \\n \\n\", confusion_LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD CODE TO NORMALIZE CONFUSION MATRIX AND PRINT THE NORMALIZED MATRIX\n",
    "\n",
    "print(\"\\n Confusion matrix SVM (normalized)   \\n \\n\", confusion_SVM /counts[:,None] )\n",
    "print(\"\\n Confusion matrix LR (normalized)   \\n \\n\", confusion_LR /counts[:,None] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUESTION 5\n",
    "Have a look at the confusion matrices and comment on the obtained accuracies. Why some classes have lower accuracies and others an higher one ? Make some guesses on the possible causes.\n",
    "\n",
    "As we can see the labels with the highest true positive(TP)/accuracy (>=90) are 1-Trouser, 5-Sandal, 8-Bag, 9-Ankle Boot. After I compared these labels and check their images on the dataset, I saw that images that belong to these 4 classes have very unique characteristics. For example, a bag, or a trouser has very unique shapes among other images that have different labels. So, they can be predicted and learned easier than others. \n",
    "\n",
    "When we check lower accuracy ones, we see that label 6-Shirt has 54% TP/accuracy (SVM). When we check the confusion matrix, we see that 8% of shirts are labeled as 0-T-shirt and 11% of them are labeled as 2-Pullover. When I checked the images, even I sometimes confused while labeling the image as Shirt because Shirts do not have huge unique characteristics that separate them from all other labels. Another example is, label 2-Pullover is labeled with 66% accuracy(LR) and the 12% of them are labeled as 6-Shirt. \n",
    "\n",
    "To sum up, labels that have similar characteristics have lower accuracy while labels that have unique characteristics like the bag has high accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
